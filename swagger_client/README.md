# convolutional_autoencoder

ConvolutionalAutoencoder - JavaScript client for convolutional_autoencoder
WebUI to build, train and tune a Convolutional Autoencoder
This SDK is automatically generated by the [Swagger Codegen](https://github.com/swagger-api/swagger-codegen) project:

- API version: 1.0.7
- Package version: 1.0.7
- Build package: io.swagger.codegen.languages.JavascriptClientCodegen

## Installation

### For [Node.js](https://nodejs.org/)

#### npm

To publish the library as a [npm](https://www.npmjs.com/),
please follow the procedure in ["Publishing npm packages"](https://docs.npmjs.com/getting-started/publishing-npm-packages).

Then install it via:

```shell
npm install convolutional_autoencoder --save
```

##### Local development

To use the library locally without publishing to a remote npm registry, first install the dependencies by changing 
into the directory containing `package.json` (and this README). Let's call this `JAVASCRIPT_CLIENT_DIR`. Then run:

```shell
npm install
```

Next, [link](https://docs.npmjs.com/cli/link) it globally in npm with the following, also from `JAVASCRIPT_CLIENT_DIR`:

```shell
npm link
```

Finally, switch to the directory you want to use your convolutional_autoencoder from, and run:

```shell
npm link /path/to/<JAVASCRIPT_CLIENT_DIR>
```

You should now be able to `require('convolutional_autoencoder')` in javascript files from the directory you ran the last 
command above from.

#### git
#
If the library is hosted at a git repository, e.g.
https://github.com/YOUR_USERNAME/convolutional_autoencoder
then install it via:

```shell
    npm install YOUR_USERNAME/convolutional_autoencoder --save
```

### For browser

The library also works in the browser environment via npm and [browserify](http://browserify.org/). After following
the above steps with Node.js and installing browserify with `npm install -g browserify`,
perform the following (assuming *main.js* is your entry file, that's to say your javascript file where you actually 
use this library):

```shell
browserify main.js > bundle.js
```

Then include *bundle.js* in the HTML pages.

### Webpack Configuration

Using Webpack you may encounter the following error: "Module not found: Error:
Cannot resolve module", most certainly you should disable AMD loader. Add/merge
the following section to your webpack config:

```javascript
module: {
  rules: [
    {
      parser: {
        amd: false
      }
    }
  ]
}
```

## Getting Started

Please follow the [installation](#installation) instruction and execute the following JS code:

```javascript
var ConvolutionalAutoencoder = require('convolutional_autoencoder');

var api = new ConvolutionalAutoencoder.BuildApi()

var inputParameters = new ConvolutionalAutoencoder.ParameterList(); // {ParameterList} object with all tunable parameters


var callback = function(error, data, response) {
  if (error) {
    console.error(error);
  } else {
    console.log('API called successfully.');
  }
};
api.buildANN(inputParameters, callback);

```

## Documentation for API Endpoints

All URIs are relative to *http://localhost:8080/v2*

Class | Method | HTTP request | Description
------------ | ------------- | ------------- | -------------
*ConvolutionalAutoencoder.BuildApi* | [**buildANN**](docs/BuildApi.md#buildANN) | **POST** /build/buildANN | passes all learning and ANN parameters to the server
*ConvolutionalAutoencoder.BuildApi* | [**getInputShape**](docs/BuildApi.md#getInputShape) | **GET** /build/getInputShape | returns the input shape of the train data
*ConvolutionalAutoencoder.LoadApi* | [**getImageBatch**](docs/LoadApi.md#getImageBatch) | **GET** /load/getImageBatch | returns the next batch of input/output images
*ConvolutionalAutoencoder.LoadApi* | [**getImageById**](docs/LoadApi.md#getImageById) | **GET** /load/getImageById | returns a single input/output image
*ConvolutionalAutoencoder.LoadApi* | [**getImages**](docs/LoadApi.md#getImages) | **GET** /load/getImages | returns a subset of input/output images
*ConvolutionalAutoencoder.LoadApi* | [**getRandomImages**](docs/LoadApi.md#getRandomImages) | **GET** /load/getRandomImages | returns the next batch of input/output images
*ConvolutionalAutoencoder.LoadApi* | [**loadFile**](docs/LoadApi.md#loadFile) | **POST** /load/loadFile | Load a train/test data file
*ConvolutionalAutoencoder.LoadApi* | [**resetAllBatchIndices**](docs/LoadApi.md#resetAllBatchIndices) | **POST** /load/resetAllBatchIndices | resets all batch indices of all image sets
*ConvolutionalAutoencoder.LoadApi* | [**resetBatchIndex**](docs/LoadApi.md#resetBatchIndex) | **POST** /load/resetBatchIndex | resets the batch index of the image set
*ConvolutionalAutoencoder.TrainApi* | [**controlTraining**](docs/TrainApi.md#controlTraining) | **POST** /train/controlTraining | starts, pauses and stops the training
*ConvolutionalAutoencoder.TrainApi* | [**getProcessedImageData**](docs/TrainApi.md#getProcessedImageData) | **GET** /train/getProcessedImageData | returns a subset of the current train images and the corresponding latent representation and output
*ConvolutionalAutoencoder.TrainApi* | [**getTrainPerformance**](docs/TrainApi.md#getTrainPerformance) | **GET** /train/getTrainPerformance | returns the next batch of scalar train variables
*ConvolutionalAutoencoder.TuneApi* | [**controlTuning**](docs/TuneApi.md#controlTuning) | **PUT** /tune/controlTuning | starts, pauses and stops the tuning
*ConvolutionalAutoencoder.TuneApi* | [**getProcessedImageDataOfCurrentTuning**](docs/TuneApi.md#getProcessedImageDataOfCurrentTuning) | **GET** /tune/getProcessedImageDataOfCurrentTuning | returns a subset of the current train images and the corresponding latent representation and output
*ConvolutionalAutoencoder.TuneApi* | [**getTrainPerformanceOfCurrentTuning**](docs/TuneApi.md#getTrainPerformanceOfCurrentTuning) | **GET** /tune/getTrainPerformanceOfCurrentTuning | returns the next batch of scalar train variables
*ConvolutionalAutoencoder.TuneApi* | [**passANNParameterLists**](docs/TuneApi.md#passANNParameterLists) | **POST** /tune/buildGridSearchANN | passes all learning and ANN parameters to the server
*ConvolutionalAutoencoder.VisualizeApi* | [**generateImageFromSinglePoint**](docs/VisualizeApi.md#generateImageFromSinglePoint) | **GET** /visualize/generateImageFromSinglePoint | generates the AE output from a given point of the sample distribution
*ConvolutionalAutoencoder.VisualizeApi* | [**getHiddenLayerLatentClustering**](docs/VisualizeApi.md#getHiddenLayerLatentClustering) | **GET** /visualize/getHiddenLayerLatentClustering | returns the clustering of the latent representation of a hidden layer


## Documentation for Models

 - [ConvolutionalAutoencoder.ClusterParameters](docs/ClusterParameters.md)
 - [ConvolutionalAutoencoder.Clustering](docs/Clustering.md)
 - [ConvolutionalAutoencoder.CostFunction](docs/CostFunction.md)
 - [ConvolutionalAutoencoder.Image](docs/Image.md)
 - [ConvolutionalAutoencoder.ImageData](docs/ImageData.md)
 - [ConvolutionalAutoencoder.LearningRate](docs/LearningRate.md)
 - [ConvolutionalAutoencoder.ParameterList](docs/ParameterList.md)
 - [ConvolutionalAutoencoder.Point2D](docs/Point2D.md)
 - [ConvolutionalAutoencoder.ProcessedImageData](docs/ProcessedImageData.md)
 - [ConvolutionalAutoencoder.RandomFunction](docs/RandomFunction.md)
 - [ConvolutionalAutoencoder.TrainPerformance](docs/TrainPerformance.md)
 - [ConvolutionalAutoencoder.TrainStatus](docs/TrainStatus.md)


## Documentation for Authorization

 All endpoints do not require authorization.

